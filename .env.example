# OpenAI API Configuration
# Use OpenAI API key or any OpenAI-compatible API key
LLM_API_KEY=your_api_key_here

# URL endpoint for the LLM API
LLM_URL=http://localhost:8000/v1

# Model name to use
# Examples: gemma-3-27b-it, etc.
LLM_MODEL=gemma-3-27b-it

# Flask and Server Configuration
# Port for the Flask application
HOST_PORT=1808

# Optional: Flask environment (development or production)
# FLASK_ENV=development

# Optional: Enable debug mode (not recommended for production)
# FLASK_DEBUG=1

# Optional: Embedding model name
# Default: isy-thl/multilingual-e5-base-course-skill-tuned
# EMBEDDING_MODEL=isy-thl/multilingual-e5-base-course-skill-tuned
